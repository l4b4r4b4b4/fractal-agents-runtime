# =============================================================================
# Fractal Agents Runtime — Production Environment Overrides
# =============================================================================
# Usage:
#   helm install agent-runtime .devops/helm/fractal-agents-runtime \
#     -f .devops/helm/fractal-agents-runtime/values-prod.yaml \
#     -n production
# =============================================================================

runtime: python

image:
  repository: ghcr.io/l4b4r4b4b4/fractal-agents-runtime-python
  tag: ""  # use Chart.appVersion for production — pin to release tag
  pullPolicy: IfNotPresent

replicaCount: 5

# Python runtime config — production tuned
python:
  host: "0.0.0.0"
  port: 8081
  workers: 4
  devMode: false
  database:
    url: ""  # MUST be provided via existingSecret
    poolMinSize: 5
    poolMaxSize: 20
    poolTimeout: 30
  agentSync:
    scope: "all"

config:
  supabase:
    url: "https://production-project.supabase.co"
  llm:
    openaiApiBase: "http://ministral-vllm.production.svc.cluster.local/v1"
    modelName: ""
  tracing:
    langchainTracingV2: "true"
    langchainProject: "production"

# Production resources — generous limits
resources:
  limits:
    cpu: 2000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# Aggressive autoscaling for production traffic
autoscaling:
  enabled: true
  minReplicas: 5
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 4
        periodSeconds: 30
      selectPolicy: Max

# PDB — always keep at least 3 pods available
podDisruptionBudget:
  enabled: true
  minAvailable: 3

# Production ingress with rate limiting and TLS
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-buffering: "off"
    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "10"
  hosts:
    - host: agent-api.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: fractal-agents-runtime-prod-tls
      hosts:
        - agent-api.example.com

# Strict security context for production
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 65532
  fsGroup: 65532
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 65532
  capabilities:
    drop:
    - ALL

# Network policy — locked down in production
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
      - namespaceSelector:
          matchLabels:
            name: ingress-nginx
      ports:
      - protocol: TCP
        port: 8081
  extraEgress:
    # Allow vLLM backend
    - to:
      - namespaceSelector:
          matchLabels:
            name: production
        podSelector:
          matchLabels:
            app: ministral-vllm
      ports:
      - protocol: TCP
        port: 80

# Enable monitoring in production
serviceMonitor:
  enabled: true
  interval: 30s
  scrapeTimeout: 10s

prometheusRule:
  enabled: true

# Strict anti-affinity — spread pods across nodes
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
    - labelSelector:
        matchExpressions:
        - key: app.kubernetes.io/name
          operator: In
          values:
          - fractal-agents-runtime
      topologyKey: kubernetes.io/hostname
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      preference:
        matchExpressions:
        - key: node-role.kubernetes.io/compute
          operator: In
          values:
          - "true"

# Production-specific labels
podLabels:
  environment: production
