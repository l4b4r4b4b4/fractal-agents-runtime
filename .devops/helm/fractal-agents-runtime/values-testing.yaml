# =============================================================================
# Fractal Agents Runtime — AKS Testing Environment Overrides
# =============================================================================
# Namespace: testing
# Supabase: supabase-test (internal Kubernetes DNS)
# vLLM: ministral-vllm (internal Kubernetes DNS)
#
# Usage:
#   helm install agent-runtime .devops/helm/fractal-agents-runtime \
#     -f .devops/helm/fractal-agents-runtime/values-testing.yaml \
#     -n testing
# =============================================================================

runtime: python

image:
  repository: ghcr.io/l4b4r4b4b4/fractal-agents-runtime-python
  tag: "development"
  pullPolicy: Always

replicaCount: 1

# Use existing Supabase JWT secret from the testing namespace
existingSecret:
  name: "supabase-test-jwt"
  keys:
    supabaseKey: "anonKey"
    supabaseSecret: "secret"
    supabaseJwtSecret: "jwtSecret"
    # LLM keys not needed — using local vLLM
    openaiApiKey: ""
    anthropicApiKey: ""
    langchainApiKey: ""
    langfuseSecretKey: ""
    langfusePublicKey: ""
    databaseUrl: "databaseUrl"

# Do not create Helm-managed secrets — we use the existing Supabase secret
secrets:
  create: false

# Python runtime config
python:
  host: "0.0.0.0"
  port: 8081
  workers: 2
  devMode: true
  database:
    url: ""  # provided via existingSecret
    poolMinSize: 1
    poolMaxSize: 5
    poolTimeout: 30
  agentSync:
    scope: "none"

config:
  supabase:
    # Use internal Kubernetes DNS for Supabase Kong API gateway
    url: "http://supabase-test-supabase-kong.testing.svc.cluster.local:8000"
  llm:
    # Use local ministral vLLM in testing namespace
    openaiApiBase: "http://ministral-vllm.testing.svc.cluster.local/v1"
    modelName: "ministral"
  tracing:
    langchainTracingV2: "false"
    langchainProject: "testing"

# Minimal resources for testing
resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 250m
    memory: 512Mi

# Disable autoscaling for single-replica testing
autoscaling:
  enabled: false

# Disable PDB for single replica
podDisruptionBudget:
  enabled: false

# No ingress — no public exposure for testing
ingress:
  enabled: false

# Simplified service
service:
  type: ClusterIP
  port: 80

# Relaxed security for testing (allow filesystem writes for debug)
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 65532
  fsGroup: 65532

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  runAsUser: 65532

# Disable network policy for easier testing
networkPolicy:
  enabled: false

# Disable monitoring (no Prometheus Operator in testing)
serviceMonitor:
  enabled: false

prometheusRule:
  enabled: false

# Faster health checks for testing
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 15
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 5

readinessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Testing-specific labels
podLabels:
  environment: testing

# No scheduling constraints for testing
nodeSelector: {}
tolerations: []
affinity: {}

# Debug logging + unbuffered output
env:
  - name: LOG_LEVEL
    value: "DEBUG"
  - name: PYTHONUNBUFFERED
    value: "1"
