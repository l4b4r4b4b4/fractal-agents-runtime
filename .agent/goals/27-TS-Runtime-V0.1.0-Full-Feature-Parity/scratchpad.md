# Goal 27: TS Runtime v0.1.0 — Full Python Feature Parity

> **Status:** ⚪ Not Started
> **Priority:** High
> **Created:** 2026-02-15
> **Last Updated:** 2026-02-15
> **Depends on:** [Goal 26 — TS Runtime v0.0.3](../26-TS-Runtime-V0.0.3-MCP-Tracing-Crons/scratchpad.md)

---

## Objectives

Complete the TypeScript runtime's journey to **full feature parity** with the Python runtime. After this goal, the two runtimes are interchangeable — same API surface, same agent graphs, same operational capabilities. The Helm chart's `runtime` toggle becomes a real production choice between Python (Robyn) and TypeScript (Bun).

1. **A2A protocol** — Agent-to-Agent communication endpoint (`/a2a/{assistant_id}`) — the final 1 path, 1 operation from the Python OpenAPI spec
2. **Research agent graph** — Two-phase parallel research with human-in-the-loop review, porting `graphs/research_agent/` from Python
3. **Graph registry parity** — Lazy-loading, extensible registry with both `"agent"` and `"research_agent"` built-in
4. **RAG tool integration** — Supabase-based retrieval-augmented generation tool factory
5. **Langfuse prompt templates** — Port `infra/prompts.py` for template-driven system prompts
6. **Full CI quality gates** — Test coverage enforcement, diff-cover, OpenAPI validation, lint — matching Python's 867-test quality bar
7. **Production-grade Docker + Helm** — Complete Helm chart parity, multi-stage Docker with all features

---

## Scope: What's in v0.1.0

### Final API Endpoint (from Python OpenAPI spec)

#### A2A Protocol (1 path, 1 operation)

| Path | Method | operationId | Description |
|------|--------|-------------|-------------|
| `/a2a/{assistant_id}` | POST | `a2aPost` | Agent-to-Agent JSON-RPC 2.0 protocol handler |

The A2A endpoint supports multiple methods:
- `message/send` — Send a message to an agent, get response (blocking)
- `message/send/stream` — Send a message, stream response (SSE)
- `tasks/get` — Get task status by ID and contextId
- `tasks/cancel` — Cancel a running task

Request format: JSON-RPC 2.0 with `method`, `params.message` (role, parts, messageId, contextId)
Response format: JSON-RPC 2.0 with task result (kind, id, contextId, status, artifacts)

#### Final Endpoint Count

| Category | Paths | Operations | Source |
|----------|-------|------------|--------|
| System | 5 | 5 | Goal 03 |
| Assistants | 4 | 6 | Goal 03 |
| Threads | 6 | 9 | Goal 03 |
| Runs stateful | 7 | 14 | Goal 03 |
| Runs stateless | 3 | 3 | Goal 03 |
| Store | 3 | 5 | Goal 25 |
| MCP | 1 | 3 | Goal 26 |
| Crons | 4 | 4 | Goal 26 |
| Metrics | 1 | 1 | Goal 26 |
| **A2A** | **1** | **1** | **This goal** |
| **Total** | **35** | **51** | **Full parity** |

This matches the Python runtime's 34 paths + `/openapi.json` = 35 paths. (Python spec has 34 documented paths; `/openapi.json` is served but not in the spec.)

### Research Agent Graph

Port `apps/python/src/graphs/research_agent/` to TypeScript:

- **Two-phase parallel architecture:**
  - Phase 1: Parallel research workers execute independent subtasks concurrently
  - Phase 2: Synthesis node aggregates worker results into final output
- **Human-in-the-loop (HIL):** Interrupt after Phase 1 for human review/approval before synthesis
- **Worker configuration:** Configurable number of parallel workers, per-worker prompts
- **State management:** Research state with worker results, synthesis output, approval status

#### Python Source Files to Port

| Python File | TypeScript Target | Description |
|-------------|-------------------|-------------|
| `graphs/research_agent/__init__.py` | `graphs/research-agent/index.ts` | Graph factory export |
| `graphs/research_agent/graph.py` | `graphs/research-agent/graph.ts` | LangGraph graph definition (nodes, edges, state) |
| `graphs/research_agent/worker.py` | `graphs/research-agent/worker.ts` | Parallel worker node implementation |
| `graphs/research_agent/models.py` | `graphs/research-agent/models.ts` | State types (ResearchState, WorkerResult, etc.) |
| `graphs/research_agent/configuration.py` | `graphs/research-agent/configuration.ts` | Research graph config (model, workers, prompts) |
| `graphs/research_agent/prompts.py` | `graphs/research-agent/prompts.ts` | Default prompt templates |

### Graph Registry Parity

Extend `src/graphs/registry.ts` to match Python's registry exactly:

- Lazy-loading via dynamic `import()` (match Python's `_lazy_import` pattern)
- Built-in registrations:
  - `"agent"` → `graphs/react-agent/agent.ts` (already in v0.0.1)
  - `"research_agent"` → `graphs/research-agent/graph.ts` (new)
- `registerGraph(graphId, { factory?, modulePath?, attribute? })` — Support both eager and lazy registration
- `resolveGraphFactory(graphId)` — Fallback chain: exact match → default (`"agent"`)
- `getAvailableGraphIds()` → `["agent", "research_agent"]`

### RAG Tool Integration

Port the Supabase RAG tool factory from the Python react agent:

- `RagConfig` type: `{ rag_url: string | null, collections: string[] | null }`
- RAG tool factory: creates a LangChain tool that queries Supabase vector store
- Collection-based retrieval: filter by collection UUIDs
- Integration with `@supabase/supabase-js` for vector similarity search
- Wired into react agent's tool list alongside MCP tools
- No-op when `rag` config is null or empty (graceful degradation)

### Langfuse Prompt Templates

Port `apps/python/src/infra/prompts.py` to TypeScript:

- `fetchPromptTemplate(promptName, config?)` — Fetch prompt from Langfuse by name
- `resolveSystemPrompt(assistantConfig)` — Resolve system prompt:
  1. Check Langfuse for named prompt template (if configured)
  2. Fall back to assistant configurable `system_prompt`
  3. Fall back to default system prompt constant
- Cache fetched templates (avoid re-fetching per invocation)
- Integration with react agent and research agent graph prompt resolution
- No-op when Langfuse not configured (uses local fallbacks)

### CI Quality Gates

Match the Python runtime's quality enforcement:

| Gate | Python | TypeScript Target |
|------|--------|-------------------|
| Tests | 867 tests, `pytest` | ≥100 tests, `bun test` |
| Coverage floor | 73% global (`pytest-cov fail_under`) | 73% global (coverage tool TBD) |
| Per-file coverage | `coverage-threshold` | Per-file floors (coverage tool TBD) |
| Diff-cover | 80% on changed lines | 80% on changed lines |
| Lint | `ruff check` + `ruff format` | `bunx tsc --noEmit` + Biome or similar |
| OpenAPI validation | 34 paths, 44 operations | 35 paths, 51 operations |
| Branch protection | CI required for `main` + `development` | Same |

### Helm Chart Parity

The unified Helm chart (`.devops/helm/fractal-agents-runtime/`) already supports `runtime: ts` via `values-ts.yaml`. This goal ensures it works correctly with all new features:

- Verify all env vars propagated correctly (Langfuse, MCP, agent sync, etc.)
- Health check probe hits `/health` correctly
- Readiness probe verifies full startup (including agent sync)
- Resource limits appropriate for Bun single-process model
- ConfigMap / Secret references for all new env vars

---

## Architecture Changes

```
apps/ts/src/
├── ... (existing from v0.0.1 + v0.0.2 + v0.0.3)
├── infra/
│   ├── tracing.ts              # (existing from v0.0.3)
│   ├── store-namespace.ts      # (existing from v0.0.2)
│   ├── prompts.ts              # NEW: Langfuse prompt template resolution
│   └── security/
│       └── auth.ts             # (existing from v0.0.2)
├── graphs/
│   ├── registry.ts             # (updated) Lazy loading + research_agent registration
│   ├── react-agent/
│   │   ├── agent.ts            # (updated) RAG tool integration
│   │   ├── configuration.ts    # (updated) RagConfig type
│   │   ├── providers.ts        # (existing from v0.0.2)
│   │   └── utils/
│   │       ├── mcp-tools.ts    # (existing from v0.0.3)
│   │       └── rag-tools.ts    # NEW: RAG tool factory
│   └── research-agent/         # NEW: Entire directory
│       ├── index.ts            # Graph factory export
│       ├── graph.ts            # LangGraph graph (nodes, edges, state channels)
│       ├── worker.ts           # Parallel research worker node
│       ├── models.ts           # ResearchState, WorkerResult, SynthesisResult types
│       ├── configuration.ts    # ResearchGraphConfig type
│       └── prompts.ts          # Default prompt templates for research
├── a2a/                        # NEW: Agent-to-Agent protocol
│   ├── handlers.ts             # A2A JSON-RPC method dispatch
│   └── schemas.ts              # A2A request/response types (Task, Message, Artifact)
├── routes/
│   ├── ... (existing)
│   └── a2a.ts                  # NEW: /a2a/{assistant_id} route
└── tests/
    ├── ... (existing)
    ├── a2a.test.ts             # NEW: A2A protocol tests
    ├── research-agent.test.ts  # NEW: Research agent graph tests
    ├── rag-tools.test.ts       # NEW: RAG tool factory tests
    ├── prompts.test.ts         # NEW: Prompt template tests
    └── registry.test.ts        # NEW: Graph registry tests
```

---

## Dependencies (new npm packages)

```json
{
  "cron-parser": "latest"
}
```

Note: Most dependencies are already added in prior goals. The research agent and A2A protocol use existing `@langchain/*` packages. RAG uses `@supabase/supabase-js` (already added in Goal 25). Langfuse prompt templates use `langfuse` (already added in Goal 26).

---

## Task Breakdown

### Task-01: Research Agent Graph

**Goal:** Port the Python research agent to TypeScript — two-phase parallel research with HIL.

**Deliverables:**
- `src/graphs/research-agent/models.ts`:
  - `WorkerResult` type (worker_id, query, findings, sources, status)
  - `SynthesisResult` type (summary, key_findings, sources, confidence)
  - `ResearchState` type (LangGraph state channels):
    - `messages` (message list with add reducer)
    - `research_query` (string)
    - `worker_configs` (WorkerConfig[])
    - `worker_results` (WorkerResult[] with add reducer)
    - `synthesis` (SynthesisResult | null)
    - `approval_status` ("pending" | "approved" | "rejected" | null)
    - `final_output` (string | null)
  - `WorkerConfig` type (worker_id, sub_query, instructions)
- `src/graphs/research-agent/configuration.ts`:
  - `ResearchGraphConfig` type extending base GraphConfig:
    - `num_workers` (default: 3)
    - `research_prompt` (system prompt for research planning)
    - `worker_prompt` (system prompt for individual workers)
    - `synthesis_prompt` (system prompt for synthesis)
    - `require_approval` (default: true — enables HIL)
- `src/graphs/research-agent/prompts.ts`:
  - `DEFAULT_RESEARCH_PROMPT` — Planning prompt that decomposes query into sub-tasks
  - `DEFAULT_WORKER_PROMPT` — Worker prompt template (with `{sub_query}` placeholder)
  - `DEFAULT_SYNTHESIS_PROMPT` — Synthesis prompt that aggregates worker results
- `src/graphs/research-agent/worker.ts`:
  - `createWorkerNode(workerConfig, graphConfig)` → LangGraph node function
  - Worker invokes LLM with sub-query + worker-specific instructions
  - Returns `WorkerResult` with findings and sources
  - Error handling: failed worker returns error result (doesn't crash graph)
- `src/graphs/research-agent/graph.ts`:
  - LangGraph `StateGraph` definition with channels from `ResearchState`
  - Nodes:
    - `plan` — Decomposes research query into worker sub-tasks
    - `research` — Fan-out: runs N workers in parallel (using LangGraph's `Send`)
    - `worker` — Individual worker execution (receives `WorkerConfig`, returns `WorkerResult`)
    - `review` — HIL interrupt point: presents worker results for human approval
    - `synthesize` — Aggregates approved worker results into final output
    - `respond` — Formats final output as AI message
  - Edges:
    - `plan` → `research` (conditional: if workers configured)
    - `research` → `review` (after all workers complete)
    - `review` → `synthesize` (if approved) / `respond` with rejection message (if rejected)
    - `synthesize` → `respond`
    - `respond` → `END`
  - `interrupt_before: ["review"]` when `require_approval: true`
- `src/graphs/research-agent/index.ts`:
  - `graph(config, { checkpointer?, store? })` → compiled graph
  - Same factory signature as react agent for registry compatibility
- Tests: graph compilation, plan node, worker execution (mocked LLM), synthesis, HIL interrupt/resume

**Acceptance:**
- [ ] Research agent graph compiles without errors
- [ ] Plan node decomposes query into worker sub-tasks
- [ ] Workers execute in parallel and return structured results
- [ ] HIL interrupt pauses graph at review node when `require_approval: true`
- [ ] Graph resumes after human approval (via `command` in RunCreate)
- [ ] Synthesis node aggregates worker results into coherent output
- [ ] Failed worker doesn't crash graph — returns error result, synthesis handles it
- [ ] `require_approval: false` skips HIL interrupt
- [ ] Graph factory has same signature as react agent (registry compatible)
- [ ] Tests pass with mocked LLM (no API keys required)

### Task-02: Graph Registry Parity + Lazy Loading

**Goal:** Full registry parity with Python — lazy loading, both graphs registered.

**Deliverables:**
- `src/graphs/registry.ts` — Rewrite for full parity:
  - `GraphFactory` type: `(config, opts?: { checkpointer?, store? }) => Promise<CompiledGraph>`
  - `DEFAULT_GRAPH_ID` = `"agent"`
  - `_GRAPH_REGISTRY` Map storage
  - `_lazyImport(modulePath, attribute)` → `GraphFactory`:
    - Returns wrapper that `import()`s on first call
    - Caches imported factory after first resolution
    - Human-readable `__name__` for debugging
  - `registerGraph(graphId, opts)`:
    - Eager: `registerGraph("agent", { factory: fn })`
    - Lazy: `registerGraph("agent", { modulePath: "./react-agent/agent.js", attribute: "graph" })`
    - Validates: exactly one of `factory` or `modulePath` must be provided
  - `resolveGraphFactory(graphId)` → `GraphFactory`:
    - Exact match → return factory
    - Unknown ID → warn, fallback to `DEFAULT_GRAPH_ID`
    - Empty registry → direct import of react-agent (last resort)
  - `getAvailableGraphIds()` → sorted string[]
  - Built-in registrations (lazy):
    - `"agent"` → `./react-agent/agent.js` : `graph`
    - `"research_agent"` → `./research-agent/graph.js` : `graph`
- Update `GET /info` endpoint:
  - `graphs` field returns `getAvailableGraphIds()` → `["agent", "research_agent"]`
- Update `graph_id` enum in assistant types to include `"research_agent"`
- Tests: lazy loading, fallback, registration, resolution, available IDs

**Acceptance:**
- [ ] `resolveGraphFactory("agent")` returns react-agent factory
- [ ] `resolveGraphFactory("research_agent")` returns research-agent factory
- [ ] `resolveGraphFactory("unknown")` falls back to `"agent"` with warning
- [ ] `resolveGraphFactory(null)` returns `"agent"` factory
- [ ] Lazy loading: research-agent module only imported when first resolved
- [ ] `getAvailableGraphIds()` returns `["agent", "research_agent"]`
- [ ] `/info` endpoint reports both graph IDs
- [ ] Custom graph registration works: `registerGraph("my_graph", { factory: fn })`
- [ ] Error if both `factory` and `modulePath` provided
- [ ] Error if neither `factory` nor `modulePath` provided

### Task-03: A2A Protocol Endpoint

**Goal:** Agent-to-Agent communication via JSON-RPC 2.0 — the final endpoint for full API parity.

**Deliverables:**
- `src/a2a/schemas.ts`:
  - `A2ARequest` (jsonrpc: "2.0", id: string, method: string, params: object)
  - `A2AResponse` (jsonrpc: "2.0", id: string, result?, error?)
  - `A2AMessage` type:
    - `role` ("user" | "assistant")
    - `parts` array of `{ kind: "text", text: string }` (extensible for other content types)
    - `messageId` (string)
    - `contextId` (optional string — maps to thread_id)
  - `A2ATask` type:
    - `kind` ("task")
    - `id` (task UUID)
    - `contextId` (thread UUID)
    - `status` object: `{ state: "completed" | "failed" | "running" | "canceled" }`
    - `artifacts` array of `{ artifactId, name, parts: [{ kind: "text", text }] }`
  - Method-specific param types: `MessageSendParams`, `TasksGetParams`, `TasksCancelParams`
- `src/a2a/handlers.ts`:
  - `handleA2ARequest(request, assistantId, context)` → `A2AResponse | SSE stream`
  - Method dispatch:
    - `message/send` — Execute agent run (blocking), return task with artifacts
    - `message/send/stream` — Execute agent run (streaming), return SSE
    - `tasks/get` — Look up run by task ID + context ID, return task status + artifacts
    - `tasks/cancel` — Cancel running run by task ID
  - Mapping:
    - `contextId` → `thread_id`
    - `messageId` → `run_id` (or generate new)
    - A2A message parts → LangGraph `HumanMessage` input
    - Agent AI response → A2A artifact with text parts
  - Error handling:
    - Unknown assistant → 404
    - Unknown method → JSON-RPC error code -32601
    - Execution failure → JSON-RPC error with code and message
- `src/routes/a2a.ts`:
  - `POST /a2a/{assistant_id}` — Parse JSON-RPC, dispatch to handler
  - `assistant_id` path parameter selects which assistant/graph to invoke
  - Optional `thread_id` query parameter for conversation continuity
  - Content negotiation:
    - `message/send` → `application/json` response
    - `message/send/stream` → `text/event-stream` response
  - Auth required (uses authenticated user identity)
- Wire into router
- Tests: message/send flow, streaming, tasks/get, tasks/cancel, unknown assistant, unknown method

**Acceptance:**
- [ ] `POST /a2a/{assistant_id}` with `message/send` returns JSON-RPC task result
- [ ] Task result includes artifacts with agent's text response
- [ ] `contextId` maps to thread_id (conversation continuity)
- [ ] `message/send/stream` returns SSE stream with task events
- [ ] `tasks/get` retrieves run status as A2A task
- [ ] `tasks/cancel` cancels running run
- [ ] Unknown `assistant_id` → 404
- [ ] Unknown method → JSON-RPC error -32601
- [ ] Auth required (401 without token)
- [ ] Response shapes match Python implementation's examples in OpenAPI spec
- [ ] Multiple message parts supported in request

### Task-04: RAG Tool Integration

**Goal:** Supabase-based retrieval-augmented generation tool for the react agent.

**Deliverables:**
- `src/graphs/react-agent/utils/rag-tools.ts`:
  - `RagConfig` type: `{ rag_url: string | null, collections: string[] | null }`
  - `createRagTool(ragConfig, supabaseClient)` → `BaseTool | null`
  - Creates a `DynamicStructuredTool` that:
    - Accepts a `query` string input
    - Calls Supabase vector similarity search against specified collections
    - Returns matching document chunks as formatted context
  - Input schema: `{ query: z.string().describe("Search query for knowledge base") }`
  - Collection filtering: only searches specified collection UUIDs
  - Returns `null` if `ragConfig` is null or has no collections (graceful no-op)
  - Error handling: search failure returns error message as tool result (doesn't throw)
- `src/graphs/react-agent/agent.ts` — Updated:
  - Extract `rag` config from assistant configurable
  - Call `createRagTool()` if RAG configured
  - Add RAG tool to tool list alongside MCP tools
  - Tool ordering: built-in tools → RAG tool → MCP tools
- `src/graphs/react-agent/configuration.ts` — Add `RagConfig` type + `rag` field to `GraphConfig`
- Tests: tool creation, search execution (mocked Supabase), no-config graceful no-op, error handling

**Acceptance:**
- [ ] RAG tool created when `rag` config has url + collections
- [ ] RAG tool returns `null` when config is null (no-op)
- [ ] Tool executes vector similarity search against Supabase
- [ ] Results filtered by collection UUIDs
- [ ] Search failure returns error message (doesn't crash agent)
- [ ] Agent uses RAG tool for knowledge retrieval when configured
- [ ] Tool description is clear for LLM understanding
- [ ] Tests pass with mocked Supabase (no real connection needed)

### Task-05: Langfuse Prompt Templates

**Goal:** Template-driven system prompts via Langfuse, matching Python's `infra/prompts.py`.

**Deliverables:**
- `src/infra/prompts.ts`:
  - `fetchPromptTemplate(promptName: string, options?)` → `string | null`
    - Fetches prompt from Langfuse by name
    - Caches fetched templates (in-memory, configurable TTL)
    - Returns `null` if Langfuse not configured or prompt not found
    - Version support: fetch specific version or latest
  - `resolveSystemPrompt(assistantConfig: Record<string, unknown>)` → `string`
    - Resolution order:
      1. Langfuse named prompt (if `prompt_template_name` in configurable)
      2. Literal `system_prompt` from configurable
      3. Default system prompt constant
    - Variable interpolation in templates (simple `{variable}` replacement)
  - `DEFAULT_SYSTEM_PROMPT` — Same default as Python runtime
  - `UNEDITABLE_SYSTEM_PROMPT` — Appended to all system prompts (safety/formatting instructions)
  - Cache management: `clearPromptCache()` for testing
- Update `src/graphs/react-agent/agent.ts`:
  - Use `resolveSystemPrompt()` instead of direct `system_prompt` field read
  - Pass assistant configurable for template resolution
- Update `src/graphs/research-agent/graph.ts`:
  - Use `resolveSystemPrompt()` for research/worker/synthesis prompts
- Tests: Langfuse fetch (mocked), cache behavior, resolution order, variable interpolation, default fallback

**Acceptance:**
- [ ] `fetchPromptTemplate("my-prompt")` returns template text from Langfuse
- [ ] Cached templates don't re-fetch within TTL
- [ ] `resolveSystemPrompt()` follows correct priority order (Langfuse → literal → default)
- [ ] Variable interpolation: `"Hello {name}"` with `{name: "World"}` → `"Hello World"`
- [ ] Returns default prompt when Langfuse not configured
- [ ] Returns default prompt when named template not found
- [ ] `UNEDITABLE_SYSTEM_PROMPT` appended to all resolved prompts
- [ ] React agent uses resolved prompts
- [ ] Research agent uses resolved prompts for all phases
- [ ] Tests pass without Langfuse connection

### Task-06: CI Quality Gates, Docker & Release

**Goal:** Full CI pipeline with Python-equivalent quality gates, production Docker image, and v0.1.0 release.

**Deliverables:**
- **Test coverage enforcement:**
  - Configure coverage tool for Bun (e.g., `bun test --coverage` or `c8`)
  - Global coverage floor: 73% (matching Python)
  - Coverage report generation (lcov format for CI)
  - Diff-cover on changed lines: 80% minimum
  - Per-file coverage floors for critical modules
- **Lint enforcement:**
  - `bunx tsc --noEmit` — zero TypeScript errors
  - Consider adding Biome or ESLint for additional linting
  - Format check (Biome format or Prettier)
- **OpenAPI validation:**
  - Script to validate `openapi-spec.json` matches runtime routes
  - Verify 35 paths, 51 operations
  - Verify all component schemas present
  - Committed spec must match runtime-served spec
- **CI workflow updates** (`.github/workflows/`):
  - Add TS test + coverage step
  - Add TS lint step
  - Add TS OpenAPI validation step
  - Add diff-cover step for TS
  - Add coverage badge for TS
  - All gates must pass before merge to `development` or `main`
- **Docker image:**
  - Update `.devops/docker/ts.Dockerfile`:
    - Multi-stage: install deps → build → production
    - Non-root user (`appuser`)
    - `HEALTHCHECK CMD curl -f http://localhost:3000/health || exit 1`
    - `EXPOSE 3000`
    - All env vars documented in Dockerfile comments
    - Image size optimization (remove dev deps, use `--production`)
  - Verify image starts and serves all 35 paths
  - Verify image works with external Postgres + Supabase
- **Helm chart verification:**
  - Verify `values-ts.yaml` includes all new env var references
  - Verify health/readiness probes work
  - Test deployment with `helm template` (dry run)
  - Update Helm chart version if needed
- **Release:**
  - Bump `package.json` version to `0.1.0`
  - CHANGELOG.md comprehensive entry for v0.1.0
  - Git tag `ts-v0.1.0`
  - GHCR image: `ghcr.io/l4b4r4b4b4/fractal-agents-runtime-ts:v0.1.0`
  - Update `README.md` to reflect TS runtime is at feature parity
  - Update Helm chart README with TS-specific documentation

**Acceptance:**
- [ ] `bun test` runs ≥100 tests with zero failures
- [ ] Coverage ≥73% globally
- [ ] Diff-cover ≥80% on new/changed lines
- [ ] `bunx tsc --noEmit` passes with zero errors
- [ ] OpenAPI spec validates: 35 paths, 51 operations, all schemas present
- [ ] Docker image builds successfully
- [ ] Docker health check passes
- [ ] Docker image size reasonable (< 200MB)
- [ ] Helm template renders correctly with `runtime: ts`
- [ ] All CI quality gates pass in pipeline
- [ ] GHCR image tagged `v0.1.0`
- [ ] CHANGELOG.md updated
- [ ] README.md reflects feature parity
- [ ] `package.json` version is `0.1.0`

---

## Success Criteria

- [ ] **Full API parity** — 35 paths, 51 operations, matching Python OpenAPI spec exactly
- [ ] **Research agent works** — Parallel workers, HIL interrupt/resume, synthesis
- [ ] **A2A protocol works** — message/send, message/send/stream, tasks/get, tasks/cancel
- [ ] **RAG tool works** — Agent retrieves context from Supabase vector store
- [ ] **Prompt templates work** — Langfuse-driven system prompts with cache + fallbacks
- [ ] **Graph registry complete** — Both `"agent"` and `"research_agent"` registered with lazy loading
- [ ] **CI quality gates** — Coverage, diff-cover, lint, OpenAPI validation all enforced
- [ ] **Production Docker** — Multi-stage, non-root, health check, all features working
- [ ] **Helm chart works** — `runtime: ts` deploys correctly with all env vars
- [ ] **README updated** — Documents TS runtime at feature parity
- [ ] **Interchangeable runtimes** — Client can switch between Python and TS without code changes

---

## Risk Assessment

| Risk | Impact | Mitigation |
|------|--------|------------|
| LangGraph.js `Send` API for parallel workers differs from Python | High | Verify JS API for fan-out/fan-in patterns; adapt graph structure if needed |
| LangGraph.js `interrupt_before` for HIL may differ from Python | High | Verify JS interrupt/resume API; test with actual interrupt → command → resume flow |
| A2A protocol spec ambiguity (emerging standard) | Medium | Match Python implementation exactly; A2A spec still evolving |
| Bun test coverage tooling maturity | Medium | `bun test --coverage` may have limitations; fallback to `c8` or `istanbul` |
| RAG tool Supabase vector search JS API | Medium | Verify `@supabase/supabase-js` supports vector similarity; may need `pgvector` extension |
| Langfuse JS prompt API differs from Python | Low | Langfuse JS SDK well-documented; verify `getPrompt()` API exists |
| Docker image size with all `@langchain/*` packages | Low | Multi-stage build strips dev deps; Bun binary is already small |
| Helm chart env var proliferation (20+ env vars) | Low | Group in ConfigMap/Secret; document in Helm README |

---

## Feature Parity Verification Checklist

Before declaring v0.1.0 complete, verify each Python feature exists in TypeScript:

### Server Layer
- [ ] Robyn HTTP server → Bun.serve() HTTP server
- [ ] 34 paths, 44 operations → 35 paths, 51 operations (superset — includes `/openapi.json`)
- [ ] Supabase JWT auth middleware
- [ ] In-memory storage (fallback)
- [ ] Postgres storage (production)
- [ ] Agent sync from Supabase (startup + lazy)
- [ ] OpenAPI spec generation and serving
- [ ] Prometheus metrics endpoint
- [ ] Graceful shutdown (SIGTERM/SIGINT)

### Graph Layer
- [ ] ReAct agent (createReactAgent)
- [ ] Research agent (parallel workers, HIL, synthesis)
- [ ] Graph registry (lazy loading, extensible, fallback)
- [ ] Multi-provider LLM (OpenAI, Anthropic, Google, custom)
- [ ] MCP tool integration (dynamic loading, OAuth)
- [ ] RAG tool integration (Supabase vector search)
- [ ] Configurable system prompts (with UI config metadata)

### Infra Layer
- [ ] Langfuse tracing (initialize, inject, shutdown)
- [ ] Langfuse prompt templates (fetch, cache, resolve)
- [ ] Store namespace conventions (4-component tuple)
- [ ] Supabase auth (security module)

### Protocol Layer
- [ ] MCP server endpoint (`/mcp/` — JSON-RPC 2.0)
- [ ] A2A endpoint (`/a2a/{assistant_id}` — JSON-RPC 2.0)
- [ ] Crons API (`/runs/crons/*` — scheduled runs)
- [ ] SSE streaming (stateful + stateless + reconnect)

### DevOps
- [ ] Docker image (multi-stage, non-root, health check)
- [ ] Helm chart (`runtime: ts` toggle)
- [ ] CI pipeline (tests, coverage, lint, OpenAPI validation)
- [ ] GHCR image publishing
- [ ] Branch protection (CI required)

---

## Notes

- v0.1.0 is a significant milestone — it's the first version where the TS runtime can **fully replace** the Python runtime in production. The Helm chart's `runtime` toggle becomes a real choice.
- The research agent is the most complex graph to port. LangGraph.js's fan-out/fan-in patterns using `Send()` must be verified against the Python implementation. The HIL (human-in-the-loop) interrupt/resume flow is the trickiest part — it requires checkpoint persistence and `command` handling in the run create endpoint.
- The A2A protocol is still an emerging standard. Our implementation matches the Python runtime exactly — it's JSON-RPC 2.0 with specific method names and response shapes. Keeping parity with Python is more important than following any external A2A spec.
- After v0.1.0, both runtimes can evolve independently — new features should be added to both runtimes simultaneously (or with documented gaps). The shared OpenAPI spec and Helm chart enforce contract compatibility.
- The jump from v0.0.3 → v0.1.0 (skipping v0.0.4–v0.0.9) signals: "this is a materially different maturity level." v0.1.0 means "feature-complete, production-deployable, but still pre-1.0 (API may change)."
- Consider writing a conformance test suite that runs the same HTTP requests against both Python and TS runtimes and compares responses. This would be the ultimate parity verification.